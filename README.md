# ChatGPT/LangChainによるチャットシステム構築［実践］入門

このリポジトリは [こちら](https://github.com/yoshidashingo/langchain-book)
で公開されているコードのTypeScript で実施したリポジトリです。 deno
で実行しています。

## ●第4章 　LangChainの基礎

### 4.1 LangChainの概要

### 4.2 Language models

### 4.3 Prompts

### 4.4 Output parsers

### 4.5 Chains

### 4.6 Memory

## ●第5章　LangChainの活用

### 5.1 Data connection

### 5.2 Agents

## ●第6章　外部検索、履歴を踏まえた応答をするWebアプリの実装

### 6.1 第6章で実装するアプリケーション

### 6.2 Cloud9を起動して開発環境を構築する

### 6.3 StreamlitのHello World

### 6.4 ユーザーの入力を受け付ける

### 6.5 入力内容と応答を画面に表示する

### 6.6 会話履歴を表示する

### 6.7 LangChainを使ってOpenAIのChat Completions APIを実行する

### 6.8 Agentを使って必要に応じて外部情報を検索させる

### 6.9 チャットの会話履歴をふまえて応答する

### 6.10 Streamlit Community Cloudにデプロイする

## ●第7章　ストリーム形式で履歴を踏まえた応答をするSlackアプリの実装

### 7.1 なぜSlackアプリを作るのか

### 7.2 環境準備

### 7.3 環境設定ファイルを作成する

### 7.4 Slackアプリを新規作成する

### 7.5 ソケットモードを有効化する

### 7.6 アプリケーションを作成する

### 7.7 イベントを設定する

### 7.8 アクションを送信して応答する

### 7.9 スレッド内で返信する

### 7.10 OpenAI APIを呼び出す

### 7.11 ストリーミングで応答する

### 7.12 会話履歴を保持する

### 7.13 LazyリスナーでSlackのリトライ前に単純応答を返す

### 7.14 AWS Lambdaで起動されるハンドラー関数を作成する

### 7.15 chat.update API制限を回避する

### 7.16 Slack投稿をリッチにする

### 7.17 デプロイする

### 7.18 Socket ModeからAWS Lambdaに切り替える

## ●第8章　社内文書に答えるSlackアプリの実装

### 8.1 独自の知識をChatGPTに答えさせる

### 8.2 埋め込み表現（embeddings）とは

### 8.3 実装するアプリケーションの概要

### 8.4 開発環境を構築する

### 8.5 サンプルデータの準備

### 8.6 Pineconeのセットアップ

### 8.7 ベクターデータベース（Pinecone）にベクターデータを保存する

### 8.8 Pineconeを検索して回答する

### 8.9 会話履歴も踏まえて質問できるようにする

### 8.10 ConversationalRetrievalChainを使う

## ●第9章　LLMアプリの本番リリースに向けて

### 9.1 企業で生成AIを活用していくために

### 9.2 JDLA発行『生成AIの利用ガイドライン』をもとにした自社ガイドラインの作成

### 9.3 サービスの企画・設計段階での課題

### 9.4 テスト・評価について

### 9.5 セキュリティ対策について

### 9.6 個人データ保護の観点

### 9.7 EUが定める禁止AI・ハイリスクAIの取り扱いの動向
